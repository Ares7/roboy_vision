{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import dlib\n",
    "import os, pickle\n",
    "import re\n",
    "import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply FaceNet to an image\n",
    "\n",
    "We'll use a pre-trained convolutional neural network on a subset of MS-Celebs-1M dataset (the dataset actually contains 100K celebs at this point). \n",
    "\n",
    "To generate the embedding we need to do the following steps:\n",
    "\n",
    "1. Read an image\n",
    "- Detect a face rectangle using Dlib face detector\n",
    "- Crop the face, and possibly rotate and stretch it to fit the required dimensions of 160x160.\n",
    "- Feed the cropped and aligned face image from the previous step into the network, and obtain the embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.mtcnn.align_dlib import AlignDlib\n",
    "align = AlignDlib('../models/dlib/shape_predictor_68_face_landmarks.dat')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def detect_face(path):\n",
    "    image = mpimg.imread(path)\n",
    "    bbs = detector(image, 1)\n",
    "    tuples = []\n",
    "    for r in bbs:\n",
    "        tuples.append((r.left(), r.top(), r.right(), r.bottom()))\n",
    "    return tuples, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPECT_SIZE = 160\n",
    "\n",
    "def align_face(image, face_box, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE):\n",
    "    assert isinstance(face_box, tuple)\n",
    "    face_rect = dlib.rectangle(*face_box)\n",
    "    landmarks = align.findLandmarks(image, face_rect)\n",
    "    alignedFace = align.align(EXPECT_SIZE, image, face_rect, \n",
    "                              landmarks=landmarks,\n",
    "                              landmarkIndices=landmarkIndices)\n",
    "    return alignedFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet Initialization Functions\n",
    "\n",
    "https://github.com/davidsandberg/facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "def load_model(model_dir, model_meta, model_content):\n",
    "    s = tf.InteractiveSession()\n",
    "    model_dir_exp = os.path.expanduser(model_dir)\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\n",
    "    saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\n",
    "    tf.get_default_graph().as_graph_def()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Facenet\n",
    "\n",
    "Pre trained model on MS-Celeb-1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dir = '../models/facenet'\n",
    "meta_file, ckpt_file = get_model_filenames(os.path.expanduser(model_dir))\n",
    "session = load_model(model_dir, meta_file, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "image_batch = graph.get_tensor_by_name(\"input:0\")\n",
    "phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "embeddings = graph.get_tensor_by_name(\"embeddings:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Processing database\n",
    "\n",
    "Load images in a database, calculate embeddings and save to file.\n",
    "\n",
    "databse format: folders with name of the person, containing images of this person underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rep_for_image_path(session, image_path):\n",
    "    global image_batch, phase_train_placeholder, embeddings\n",
    "    \n",
    "    rects, face_orig = detect_face(image_path)\n",
    "    if len(rects) > 0:\n",
    "        face = align_face(face_orig, rects[0])\n",
    "        feed_dict = { \n",
    "            image_batch: np.expand_dims(face, 0), \n",
    "            phase_train_placeholder: False }\n",
    "    \n",
    "        rep = session.run(embeddings, feed_dict=feed_dict)\n",
    "    else:\n",
    "        rep = None\n",
    "    return rep\n",
    "\n",
    "def reps_for_person(dir_name):\n",
    "    all = []\n",
    "    file_names = []\n",
    "\n",
    "    for fname in os.listdir(dir_name):\n",
    "        rep = rep_for_image_path(session, dir_name + '/' + fname)\n",
    "        if rep is not None:\n",
    "            all.append(rep[0])\n",
    "            file_names.append(fname)\n",
    "    return np.array(all), file_names\n",
    "\n",
    "def load_people_faces(dir_path, person_paths, save_file):\n",
    "    assert isinstance(person_paths, list)\n",
    "    result = []\n",
    "    all_file_names = []\n",
    "    names = []\n",
    "    i = 0\n",
    "    rep_file = save_file + '_reps.npy'\n",
    "    names_file = save_file + '_names.npy'\n",
    "    print(rep_file, flush=True)\n",
    "    if(os.path.exists(names_file) and os.path.exists(rep_file)):\n",
    "        result = np.load(rep_file).tolist()\n",
    "        names = np.load(names_file)\n",
    "        i = len(result)\n",
    "    for person_path in person_paths:\n",
    "        if person_path in names:\n",
    "            continue\n",
    "        if(i%100 == 0):\n",
    "            np.save(save_file + '_reps', result)\n",
    "            np.save(save_file + '_names', person_paths[:i] )\n",
    "        full_path = dir_path + '/' + person_path\n",
    "        #print(full_path, flush=True)\n",
    "        reps, file_names = reps_for_person(full_path)\n",
    "        #print(len(reps), flush=True)\n",
    "        print('Person ' + person_path + ' done.', flush=True)\n",
    "        result.append(reps)\n",
    "        all_file_names.append(file_names)\n",
    "        i = i+1\n",
    "    np.save(save_file + '_reps', result)\n",
    "    np.save(save_file + '_names', person_paths[:i] )\n",
    "\n",
    "def get_person_list(dir_name):\n",
    "    return os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_path = '../own_db'\n",
    "save_path = '../models/facenet_own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all folder names of persons contained in the dataset and then process all images. Save result to save_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/facenet_own_reps.npy\n",
      "Person Bill Gates done.\n",
      "Person Britney Spears done.\n",
      "Person Donald Trump done.\n",
      "Person Fabian done.\n",
      "Person Vladimir Putin done.\n"
     ]
    }
   ],
   "source": [
    "names = get_person_list(database_path)\n",
    "load_people_faces(database_path, names, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load calculated embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pre-calculated embeddings on lfw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = np.load('../models/lfw_embeddings/facenet_names.npy')\n",
    "people_reps = np.load('../models/lfw_embeddings/facenet_reps.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
