{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os, pickle\n",
    "import re\n",
    "import signal\n",
    "from models.mtcnn import detect_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Apply FaceNet to an image\n",
    "\n",
    "We'll use a pre-trained convolutional neural network on a subset of MS-Celebs-1M dataset (the dataset actually contains 100K celebs at this point). \n",
    "\n",
    "To generate the embedding we need to do the following steps:\n",
    "\n",
    "1. Read an image\n",
    "- Detect a face rectangle using Dlib face detector\n",
    "- Crop the face, and possibly rotate and stretch it to fit the required dimensions of 160x160.\n",
    "- Feed the cropped and aligned face image from the previous step into the network, and obtain the embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n",
    "minsize = 20 # minimum size of face\n",
    "threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "factor = 0.709 # scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def detect_face_mtcnn(image_path):\n",
    "    img = mpimg.imread(image_path)\n",
    "    img = img[:,:,0:3]\n",
    "    bbs, lms = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    boxes = []\n",
    "    landmarks = []\n",
    "    face_index = 0\n",
    "    for r in bbs:\n",
    "        # limit bounding box to image size\n",
    "        r[0] = np.clip(r[0],0,img.shape[0])\n",
    "        r[1] = np.clip(r[1],0,img.shape[1])\n",
    "        r[2] = np.clip(r[2],0,img.shape[0])\n",
    "        r[3] = np.clip(r[3],0,img.shape[1])\n",
    "        points = []\n",
    "        for i in range(5):\n",
    "            points.append((lms[i][face_index] , lms[i+5][face_index]))\n",
    "        landmarks.append(points)\n",
    "        boxes.append((int(r[0]) , int(r[1]) , int(r[2]) , int(r[3])))\n",
    "        #boxes.append(r[:4].astype(int).tolist())\n",
    "        face_index += 1\n",
    "    return boxes, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Align face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EXPECT_SIZE = 160\n",
    "def align_face(img, bb):\n",
    "    assert isinstance(bb, tuple)\n",
    "    cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "    scaled = misc.imresize(cropped, (EXPECT_SIZE, EXPECT_SIZE), interp='bilinear')\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Facenet Initialization Functions\n",
    "\n",
    "https://github.com/davidsandberg/facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "def load_model(model_dir, model_meta, model_content):\n",
    "    s = tf.InteractiveSession()\n",
    "    model_dir_exp = os.path.expanduser(model_dir)\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\n",
    "    saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\n",
    "    tf.get_default_graph().as_graph_def()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Facenet\n",
    "\n",
    "Pre trained model on MS-Celeb-1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_dir = '../models/facenet'\n",
    "meta_file, ckpt_file = get_model_filenames(os.path.expanduser(model_dir))\n",
    "session = load_model(model_dir, meta_file, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "image_batch = graph.get_tensor_by_name(\"input:0\")\n",
    "phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "embeddings = graph.get_tensor_by_name(\"embeddings:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Functions for Processing database\n",
    "\n",
    "Load images in a database, calculate embeddings and save to file.\n",
    "\n",
    "databse format: folders with name of the person, containing images of this person underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rep_for_image_path(session, image_path):\n",
    "    global image_batch, phase_train_placeholder, embeddings\n",
    "    \n",
    "    rects, face_orig = detect_face_mtcnn(image_path)\n",
    "    if len(rects) > 0:\n",
    "        face = align_face(face_orig, rects[0])\n",
    "        feed_dict = { \n",
    "            image_batch: np.expand_dims(face, 0), \n",
    "            phase_train_placeholder: False }\n",
    "    \n",
    "        rep = session.run(embeddings, feed_dict=feed_dict)\n",
    "    else:\n",
    "        rep = None\n",
    "    return rep\n",
    "\n",
    "def reps_for_person(dir_name):\n",
    "    all = []\n",
    "    file_names = []\n",
    "\n",
    "    for fname in os.listdir(dir_name):\n",
    "        rep = rep_for_image_path(session, dir_name + '/' + fname)\n",
    "        if rep is not None:\n",
    "            all.append(rep[0])\n",
    "            file_names.append(fname)\n",
    "    return np.array(all), file_names\n",
    "\n",
    "def load_people_faces(dir_path, person_paths, save_file):\n",
    "    assert isinstance(person_paths, list)\n",
    "    result = []\n",
    "    all_file_names = []\n",
    "    names = []\n",
    "    i = 0\n",
    "    rep_file = save_file + '_reps.npy'\n",
    "    names_file = save_file + '_names.npy'\n",
    "    print(rep_file, flush=True)\n",
    "    if(os.path.exists(names_file) and os.path.exists(rep_file)):\n",
    "        result = np.load(rep_file).tolist()\n",
    "        names = np.load(names_file)\n",
    "        i = len(result)\n",
    "    for person_path in person_paths:\n",
    "        if person_path in names:\n",
    "            continue\n",
    "        if(i%100 == 0):\n",
    "            np.save(save_file + '_reps', result)\n",
    "            np.save(save_file + '_names', person_paths[:i] )\n",
    "        full_path = dir_path + '/' + person_path\n",
    "        #print(full_path, flush=True)\n",
    "        reps, file_names = reps_for_person(full_path)\n",
    "        #print(len(reps), flush=True)\n",
    "        print('Person ' + person_path + ' done.', flush=True)\n",
    "        result.append(reps)\n",
    "        all_file_names.append(file_names)\n",
    "        i = i+1\n",
    "    np.save(save_file + '_reps', result)\n",
    "    np.save(save_file + '_names', person_paths[:i] )\n",
    "\n",
    "def get_person_list(dir_name):\n",
    "    return os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Process Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "database_path = '../datasets/own_db'\n",
    "save_path = '../models/own_embeddings/own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get all folder names of persons contained in the dataset and then process all images. Save result to save_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/own_embeddings/own_reps.npy\n",
      "Person Donald Trump done.\n",
      "Person Fabian done.\n",
      "Person George_W_Bush done.\n",
      "Person Vladimir Putin done.\n",
      "Person Britney Spears done.\n",
      "Person Bill Gates done.\n"
     ]
    }
   ],
   "source": [
    "names = get_person_list(database_path)\n",
    "load_people_faces(database_path, names, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load calculated embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading pre-calculated embeddings on lfw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "names = np.load('../models/lfw_embeddings/facenet_names.npy')\n",
    "people_reps = np.load('../models/lfw_embeddings/facenet_reps.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
