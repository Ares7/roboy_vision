{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import dlib\n",
    "import os, pickle\n",
    "import re\n",
    "import signal\n",
    "import operator\n",
    "from sklearn import svm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect face definition (DLIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from align.align_dlib import AlignDlib\n",
    "align = AlignDlib('models/dlib/shape_predictor_68_face_landmarks.dat')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def detect_face(path):\n",
    "    image = mpimg.imread(path)\n",
    "    bbs = detector(image, 1)\n",
    "    tuples = []\n",
    "    for r in bbs:\n",
    "        tuples.append((r.left(), r.top(), r.right(), r.bottom()))\n",
    "    return tuples, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align Face Definition (DLIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPECT_SIZE = 160\n",
    "\n",
    "def align_face(image, face_box, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE):\n",
    "    assert isinstance(face_box, tuple)\n",
    "    face_rect = dlib.rectangle(*face_box)\n",
    "    landmarks = align.findLandmarks(image, face_rect)\n",
    "    alignedFace = align.align(EXPECT_SIZE, image, face_rect, \n",
    "                              landmarks=landmarks,\n",
    "                              landmarkIndices=landmarkIndices)\n",
    "    return alignedFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_dir, model_meta, model_content):\n",
    "    s = tf.InteractiveSession()\n",
    "    model_dir_exp = os.path.expanduser(model_dir)\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\n",
    "    saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\n",
    "    tf.get_default_graph().as_graph_def()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'models/20170216-091149'\n",
    "meta_file, ckpt_file = get_model_filenames(os.path.expanduser(model_dir))\n",
    "session = load_model(model_dir, meta_file, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "image_batch = graph.get_tensor_by_name(\"input:0\")\n",
    "phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "embeddings = graph.get_tensor_by_name(\"embeddings:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance\n",
    "Compute euclidean distance between two data points.\n",
    "\n",
    "arguments:\n",
    "* *x1*: array of length 4; data point\n",
    "* *x2*: array of length 4; data point\n",
    "\n",
    "returns:\n",
    "* *distance*:int; euclidean distance between *x1* and *x2* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(x1, x2):\n",
    "    distance = 0\n",
    "    for i in range(len(x1)):\n",
    "        distance += pow((x1[i] - x2[i]), 2)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get k nearest neighbors\n",
    "For one data point xt compute all k nearest neighbors.\n",
    "\n",
    "arguments:\n",
    "* *X*: 2D array [no. of people, 128D feature vector]\n",
    "* *xt*: array of length 128; Test data point\n",
    "\n",
    "returns:\n",
    "* neighbors: list of length *k* of tuples (X_neighbor, class, distance between neighbor and xt); **this is the list of k nearest neighbors to xt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbours(X, xt, k):\n",
    "    distances = []\n",
    "    for person in range(len(X)):\n",
    "        for rep in range(len(X[person])):\n",
    "            dist = euclideanDistance(xt, X[person][rep])\n",
    "            distances.append((X[person][rep], person, dist))\n",
    "    distances.sort(key=operator.itemgetter(2))\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get neighbor response \n",
    "For the previously computed k nearest neighbors compute the actual response. I.e. give back the class of the majority of nearest neighbors.\n",
    "\n",
    "arguments:\n",
    "* neighbors\n",
    "\n",
    "returns\n",
    "* y: int; majority target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = np.zeros(len(neighbours[0]))\n",
    "    for n in neighbors:\n",
    "        response = n[-2]\n",
    "        classVotes[response] += 1\n",
    "    y = np.argmax(classVotes)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Functions\n",
    "\n",
    "Rearrange data to be compatible for SVM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rearrange_people_reps(people_reps):\n",
    "    all_reps = []\n",
    "    classes = []\n",
    "    for person in range(len(people_reps)):\n",
    "        for rep in range(len(people_reps[person])):\n",
    "            all_reps.append(people_reps[person][rep])\n",
    "            classes.append(person)\n",
    "    return all_reps, classes            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img = 'test_imgs/fabian.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time rects, image = detect_face(test_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(draw_rects(image, rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_face = align_face(image, rects[0], AlignDlib.INNER_EYES_AND_BOTTOM_LIP)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(aligned_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed through Facenet and get representation as 128D Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = { \n",
    "            image_batch: np.expand_dims(aligned_face, 0), \n",
    "            phase_train_placeholder: False }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time rep = session.run(embeddings, feed_dict=feed_dict)[0]\n",
    "print(rep[:10],'...', rep[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all Representation of dataset (LFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = np.load('models/facenet_names.npy')\n",
    "people_reps = np.load('models/facenet_reps.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbours = getNeighbours(people_reps, rep, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = getResponse(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification = names[output]\n",
    "distance = neighbours[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification)\n",
    "print('Distance: ' + str(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and classify with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reps, classes = rearrange_people_reps(people_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_clf = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_clf.fit(reps, classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probabilities = lin_clf.predict_proba(rep.reshape(1,-1))\n",
    "output = np.argmax(probabilities[0])\n",
    "print(probabilities[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification = names[output]\n",
    "probability = probabilities[0][output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification)\n",
    "print('Probability: ' + str(probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(reps, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probabilities = clf.predict_proba(rep.reshape(1,-1))\n",
    "output = np.argmax(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification = names[output]\n",
    "probability = probabilities[0][output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification)\n",
    "print('Probability: ' + str(probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( clf, open( \"models/tree.b\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pickle.load( open( \"models/tree.b\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = np.load('models/own_names.npy')\n",
    "people_reps = np.load('models/own_reps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "neighbours = getNeighbours(people_reps, rep, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = getResponse(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification = names[1]\n",
    "distance = neighbours[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification)\n",
    "print('Distance: ' + str(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, classes = rearrange_people_reps(people_reps)\n",
    "X = np.array(X)\n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=2, solver='eigen', shrinkage='auto')\n",
    "people_lda = lda.fit(X, classes).transform(X)\n",
    "print(X.shape, classes.shape, people_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.figure(dpi=96) # Make the chart bigger\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# A set of points for each person gets its own color\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(names)))\n",
    "plots = []\n",
    "prev = 0\n",
    "for p, color in zip(people_reps, colors):\n",
    "    s = np.array(int(p.shape[0]/2))\n",
    "    print(s)\n",
    "    person_lda = people_lda[prev:prev+p.shape[0]]\n",
    "    print(person_lda)\n",
    "    prev = p.shape[0]\n",
    "    # Split the (x, y) array into two arrays: x and y\n",
    "    x, y = tuple(np.split(person_lda, 2, axis=1))\n",
    "    plots.append(plt.scatter(x, y, color=color))\n",
    "    plt.legend(plots, names, loc='best', shadow=False, scatterpoints=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
